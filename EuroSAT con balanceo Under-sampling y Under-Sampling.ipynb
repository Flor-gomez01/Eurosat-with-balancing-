{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c08d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "El balanceo de datos es clave para evitar que el modelo se sesgue hacia las \n",
    "clases mas frecuentes y no aprenda adecuadamente las clases menos \n",
    "representadas\n",
    "\n",
    "Dos tecnicas principales\n",
    "1. over-sampling: aumenta las imagenes de las clases menos frecuentes (duplicando)\n",
    "imagenes o generando nuevas versiones a partir de las originales\n",
    "\n",
    "2. Under-sampling: Reduce las imagenes de las clases mas frecuentes (elimina \n",
    "imagenes) al azar.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c62198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over-sampling (duplicando imágenes de clases minoritarias)\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class OverSampleDataset(Dataset):\n",
    "    def __init__(self, original_dataset, target_class_size=None):\n",
    "        self.original_dataset = original_dataset\n",
    "        self.target_class_size = target_class_size if target_class_size else self._get_max_class_size()\n",
    "        \n",
    "        self.class_indices = self._get_class_indices()\n",
    "        \n",
    "        # Generamos el nuevo dataset balanceado\n",
    "        self.balanced_indices = self._apply_over_sampling()\n",
    "\n",
    "    def _get_class_indices(self):\n",
    "        class_indices = {i: [] for i in range(len(self.original_dataset.classes))}\n",
    "        for idx, (_, label) in enumerate(self.original_dataset):\n",
    "            class_indices[label].append(idx)\n",
    "        return class_indices\n",
    "\n",
    "    def _get_max_class_size(self):\n",
    "        # Devuelve el tamaño de la clase mayoritaria\n",
    "        return max(len(indices) for indices in self.class_indices.values())\n",
    "\n",
    "    def _apply_over_sampling(self):\n",
    "        balanced_indices = []\n",
    "        for label, indices in self.class_indices.items():\n",
    "            num_to_add = self.target_class_size - len(indices)\n",
    "            balanced_indices.extend(indices)  # Agregamos las imágenes originales\n",
    "            balanced_indices.extend(random.choices(indices, k=num_to_add))  # Duplicamos las imágenes de la clase\n",
    "        return balanced_indices\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.original_dataset[self.balanced_indices[index]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.balanced_indices)\n",
    "    \n",
    "        \"\"\"Explicación:\n",
    "\n",
    "    Esta clase se basa en el dataset original (EuroSAT o el que sea que este \n",
    "    usando).\n",
    "\n",
    "   ##  _get_class_indices() obtiene los índices de las imágenes para cada clase.\n",
    "\n",
    "   ## _apply_over_sampling() toma las clases menos frecuentes y las \"rellena\" \n",
    "    para igualarlas con el tamaño de la clase mayoritaria. Esto se hace \n",
    "    duplicando imágenes de las clases minoritarias usando random.choices().\n",
    "        \"\"\"\n",
    "    # Aquí, estamos creando un nuevo dataset a partir del train_dataset \n",
    "    # original, pero ahora balanceado por over-sampling usando la clase \n",
    "    # OverSampleDataset que implementamos antes. Este dataset \n",
    "    # sobre-sampleado aumentará las imágenes de las clases minoritarias \n",
    "    # hasta igualarlas al tamaño de las clases mayoritarias.\n",
    "    over_sampled_dataset = OverSampleDataset(train_dataset)\n",
    "    \n",
    "    # Con esta línea, creamos un DataLoader que nos permitirá cargar el \n",
    "    # over_sampled_dataset en batches de tamaño 16. También hemos habilitado \n",
    "    # el parámetro shuffle=True para mezclar los datos en cada época (lo que \n",
    "    # ayuda a evitar sesgos durante el entrenamiento) y configurado \n",
    "    # num_workers=2 para cargar los datos en paralelo (esto acelera la carga \n",
    "    # de datos).\n",
    "    over_sampled_loader = DataLoader(over_sampled_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71647d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under-sampling (eliminando imágenes de clases mayoritarias)\n",
    "\n",
    "class UnderSampleDataset(Dataset):\n",
    "    def __init__(self, original_dataset, target_class_size=None):\n",
    "        self.original_dataset = original_dataset\n",
    "        self.target_class_size = target_class_size if target_class_size else self._get_min_class_size()\n",
    "        \n",
    "        self.class_indices = self._get_class_indices()\n",
    "        \n",
    "        # Generamos el nuevo dataset balanceado\n",
    "        self.balanced_indices = self._apply_under_sampling()\n",
    "\n",
    "    def _get_class_indices(self):\n",
    "        class_indices = {i: [] for i in range(len(self.original_dataset.classes))}\n",
    "        for idx, (_, label) in enumerate(self.original_dataset):\n",
    "            class_indices[label].append(idx)\n",
    "        return class_indices\n",
    "\n",
    "    def _get_min_class_size(self):\n",
    "        # Devuelve el tamaño de la clase minoritaria\n",
    "        return min(len(indices) for indices in self.class_indices.values())\n",
    "\n",
    "    def _apply_under_sampling(self):\n",
    "        balanced_indices = []\n",
    "        for label, indices in self.class_indices.items():\n",
    "            num_to_remove = len(indices) - self.target_class_size\n",
    "            balanced_indices.extend(random.sample(indices, self.target_class_size))  # Reducimos imágenes\n",
    "        return balanced_indices\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.original_dataset[self.balanced_indices[index]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.balanced_indices)\n",
    "    \n",
    "        \"\"\"\n",
    "    Explicación:\n",
    "    Similar al OverSampleDataset, pero aquí reducimos el número de imágenes \n",
    "    de las clases mayoritarias a target_class_size (el tamaño de la clase \n",
    "    más pequeña).\n",
    "\n",
    "    _apply_under_sampling() selecciona aleatoriamente un número de imágenes \n",
    "    para reducir el tamaño de las clases mayoritarias, utilizando \n",
    "    random.sample().\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0add805",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnderSampleDataset(Dataset):\n",
    "    def __init__(self, original_dataset, target_class_size=None):\n",
    "        self.original_dataset = original_dataset\n",
    "        self.target_class_size = target_class_size if target_class_size else self._get_min_class_size()\n",
    "        \n",
    "        self.class_indices = self._get_class_indices()\n",
    "        \n",
    "        # Generamos el nuevo dataset balanceado\n",
    "        self.balanced_indices = self._apply_under_sampling()\n",
    "\n",
    "    def _get_class_indices(self):\n",
    "        class_indices = {i: [] for i in range(len(self.original_dataset.classes))}\n",
    "        for idx, (_, label) in enumerate(self.original_dataset):\n",
    "            class_indices[label].append(idx)\n",
    "        return class_indices\n",
    "\n",
    "    def _get_min_class_size(self):\n",
    "        # Devuelve el tamaño de la clase minoritaria\n",
    "        return min(len(indices) for indices in self.class_indices.values())\n",
    "\n",
    "    def _apply_under_sampling(self):\n",
    "        balanced_indices = []\n",
    "        for label, indices in self.class_indices.items():\n",
    "            num_to_remove = len(indices) - self.target_class_size\n",
    "            balanced_indices.extend(random.sample(indices, self.target_class_size))  # Reducimos imágenes\n",
    "        return balanced_indices\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.original_dataset[self.balanced_indices[index]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.balanced_indices)\n",
    "\n",
    "\n",
    "under_sampled_dataset = UnderSampleDataset(train_dataset)\n",
    "under_sampled_loader = DataLoader(under_sampled_dataset, batch_size=16, shuffle=True, num_workers=2)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
